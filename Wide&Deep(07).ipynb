{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([759, 8])\n",
      "torch.Size([759, 1])\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('./data/diabetes.csv', delimiter = ',', dtype = np.float32)\n",
    "x_data = Variable(torch.from_numpy(xy[:, 0: -1]))\n",
    "y_data = Variable(torch.from_numpy(xy[:, [-1]]))\n",
    "\n",
    "print (x_data.data.shape)\n",
    "print (y_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 6)\n",
    "        self.l2 = torch.nn.Linear(6, 4)\n",
    "        self.l3 = torch.nn.Linear(4, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7102838158607483\n",
      "1 0.704514741897583\n",
      "2 0.6992542743682861\n",
      "3 0.6944573521614075\n",
      "4 0.6900844573974609\n",
      "5 0.6860969066619873\n",
      "6 0.682460606098175\n",
      "7 0.679145336151123\n",
      "8 0.6761213541030884\n",
      "9 0.6733645796775818\n",
      "10 0.6708492636680603\n",
      "11 0.668555736541748\n",
      "12 0.6664625406265259\n",
      "13 0.6645528674125671\n",
      "14 0.6628104448318481\n",
      "15 0.6612207293510437\n",
      "16 0.6597684025764465\n",
      "17 0.6584432721138\n",
      "18 0.6572336554527283\n",
      "19 0.6561281085014343\n",
      "20 0.6551195383071899\n",
      "21 0.6541978716850281\n",
      "22 0.6533553004264832\n",
      "23 0.6525861620903015\n",
      "24 0.6518824696540833\n",
      "25 0.6512396335601807\n",
      "26 0.6506522297859192\n",
      "27 0.6501147150993347\n",
      "28 0.6496233344078064\n",
      "29 0.6491740942001343\n",
      "30 0.6487628817558289\n",
      "31 0.648386538028717\n",
      "32 0.6480429172515869\n",
      "33 0.6477277278900146\n",
      "34 0.6474398970603943\n",
      "35 0.6471754312515259\n",
      "36 0.6469338536262512\n",
      "37 0.6467124223709106\n",
      "38 0.6465097665786743\n",
      "39 0.6463242173194885\n",
      "40 0.6461544632911682\n",
      "41 0.6459982395172119\n",
      "42 0.6458553671836853\n",
      "43 0.645724356174469\n",
      "44 0.6456044912338257\n",
      "45 0.6454944014549255\n",
      "46 0.6453930735588074\n",
      "47 0.6453002095222473\n",
      "48 0.6452150344848633\n",
      "49 0.6451368927955627\n",
      "50 0.645065188407898\n",
      "51 0.6449997425079346\n",
      "52 0.6449391841888428\n",
      "53 0.6448833346366882\n",
      "54 0.6448321342468262\n",
      "55 0.6447848081588745\n",
      "56 0.6447416543960571\n",
      "57 0.6447020769119263\n",
      "58 0.6446647644042969\n",
      "59 0.6446317434310913\n",
      "60 0.6446007490158081\n",
      "61 0.6445717215538025\n",
      "62 0.644545316696167\n",
      "63 0.6445204615592957\n",
      "64 0.6444976925849915\n",
      "65 0.6444767713546753\n",
      "66 0.6444576382637024\n",
      "67 0.6444396376609802\n",
      "68 0.6444230675697327\n",
      "69 0.6444074511528015\n",
      "70 0.6443933844566345\n",
      "71 0.6443800926208496\n",
      "72 0.6443670988082886\n",
      "73 0.6443557143211365\n",
      "74 0.6443449854850769\n",
      "75 0.6443350911140442\n",
      "76 0.6443257331848145\n",
      "77 0.6443169116973877\n",
      "78 0.6443088054656982\n",
      "79 0.6443007588386536\n",
      "80 0.6442940831184387\n",
      "81 0.6442875266075134\n",
      "82 0.6442798972129822\n",
      "83 0.6442743539810181\n",
      "84 0.6442685723304749\n",
      "85 0.6442627310752869\n",
      "86 0.6442577838897705\n",
      "87 0.6442528367042542\n",
      "88 0.6442477703094482\n",
      "89 0.6442432999610901\n",
      "90 0.6442387700080872\n",
      "91 0.6442346572875977\n",
      "92 0.6442307829856873\n",
      "93 0.6442262530326843\n",
      "94 0.6442230343818665\n",
      "95 0.6442196369171143\n",
      "96 0.6442164182662964\n",
      "97 0.6442123651504517\n",
      "98 0.6442093253135681\n",
      "99 0.6442063450813293\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.data[0])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
